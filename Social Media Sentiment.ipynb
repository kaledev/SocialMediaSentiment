{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis of User Comments on Political Subreddits\n",
    "\n",
    "Author: Mike Kale"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this Project I'll be analyzing sentiment of various comments within the Social News website Reddit.com. The goal will be to analyze how sentiment for user comments are affected by political ideology. My source data will be comments found on Reddit.com.\n",
    "\n",
    "Test #1\n",
    "1. Pull <b>all</b> comments from 100 stories from three different political subreddits (Progressive, Conservative, NeutralPolitics)\n",
    "2. Run sentiment analysis on all three sets\n",
    "3. Compare sentiment percentage from each\n",
    "\n",
    "Test #2\n",
    "1. Pull <b>top-level</b> comments from 100 stories from three different political subreddits (Progressive, Conservative, NeutralPolitics)\n",
    "2. Run sentiment analysis on all three sets\n",
    "3. Compare sentiment percentage from each\n",
    "\n",
    "Test #2\n",
    "1. Pull same story from all three subreddits\n",
    "2. Run sentiment analysis on all three sets\n",
    "3. Compare sentiment percentage from each\n",
    "\n",
    "Some algorithms are altered from a great tutorial found here:\n",
    "www.stackovercloud.com/2019/09/27/how-to-perform-sentiment-analysis-in-python-3-using-the-natural-language-toolkit-nltk/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reddit Connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "# Connection to Reddit's API\n",
    "import pandas as pd\n",
    "import praw\n",
    "\n",
    "# I've had to clear this section out since it contains person information\n",
    "# To run this code, the person would need to go to Reddit.com and register\n",
    "#  a new application, which would provide an API key to input below.\n",
    "reddit = praw.Reddit(\n",
    "    client_id=\"<fill me out>\",\n",
    "    client_secret=\"<fill me out>\",\n",
    "    user_agent=\"SentimentTest/0.0.1\",\n",
    ")\n",
    "\n",
    "print(reddit.read_only)\n",
    "# Output: True if successful connection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NLP / Sentiment Analysis Model\n",
    "\n",
    "The following algorithm is used to cleanse the comments into a format that can be classified by a NLP model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk.corpus import twitter_samples, stopwords\n",
    "from nltk.tag import pos_tag\n",
    "from nltk.tokenize import word_tokenize, TweetTokenizer\n",
    "from nltk import FreqDist, classify, NaiveBayesClassifier\n",
    "\n",
    "import re, string, random\n",
    "\n",
    "tweet_tknzr = TweetTokenizer() #Use this over word_tokenize because of contractions\n",
    "\n",
    "def remove_noise(tokens):\n",
    "    \"\"\"\n",
    "    1. Removes 'noise' such as HTML/URL/Emojis to perform analysis\n",
    "    2. Lemmatize/Normalize like words\n",
    "    3. Remove English stop words\n",
    "    \"\"\"\n",
    "    cleaned_tokens = []\n",
    "    stop_words = stopwords.words('english')\n",
    "\n",
    "    for token, tag in pos_tag(tokens):\n",
    "        token = re.sub('http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+#]|[!*\\(\\),]|'\\\n",
    "                       '(?:%[0-9a-fA-F][0-9a-fA-F]))+','', token)\n",
    "        token = re.sub(\"(@[A-Za-z0-9_]+)\",\"\", token)\n",
    "\n",
    "        if tag.startswith(\"NN\"):\n",
    "            pos = 'n'\n",
    "        elif tag.startswith('VB'):\n",
    "            pos = 'v'\n",
    "        else:\n",
    "            pos = 'a'\n",
    "            \n",
    "        lemmatizer = WordNetLemmatizer()\n",
    "        token = lemmatizer.lemmatize(token, pos)\n",
    "\n",
    "        if len(token) > 0 and token not in string.punctuation and token.lower() not in stop_words:\n",
    "            cleaned_tokens.append(token.lower())\n",
    "    return cleaned_tokens\n",
    "\n",
    "def get_all_words(cleaned_tokens_list):\n",
    "    # Return all words from cleaned token list\n",
    "    for tokens in cleaned_tokens_list:\n",
    "        for token in tokens:\n",
    "            yield token\n",
    "\n",
    "def get_tokens_for_model(cleaned_tokens_list):\n",
    "    # Return all tokens for model classification\n",
    "    for tokens in cleaned_tokens_list:\n",
    "        yield dict([token, True] for token in tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is: 0.9956666666666667\n",
      "Most Informative Features\n",
      "                      :( = True           Negati : Positi =   2088.6 : 1.0\n",
      "                      :) = True           Positi : Negati =   1630.9 : 1.0\n",
      "                follower = True           Positi : Negati =     35.2 : 1.0\n",
      "                followed = True           Negati : Positi =     28.7 : 1.0\n",
      "                     bam = True           Positi : Negati =     20.0 : 1.0\n",
      "                     sad = True           Negati : Positi =     19.7 : 1.0\n",
      "                     x15 = True           Negati : Positi =     16.6 : 1.0\n",
      "                    miss = True           Negati : Positi =     16.0 : 1.0\n",
      "                      aw = True           Negati : Positi =     13.2 : 1.0\n",
      "                  arrive = True           Positi : Negati =     13.1 : 1.0\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Utilize Positive / Negative tweets that come packaged with\n",
    "the NLTK to help train the model for classification. This consists\n",
    "of a total of 14,000 tweets - 7000 positive and 7000 negative.\n",
    "\"\"\"\n",
    "\n",
    "positive_tweet_tokens = twitter_samples.tokenized('positive_tweets.json')\n",
    "negative_tweet_tokens = twitter_samples.tokenized('negative_tweets.json')\n",
    "\n",
    "positive_cleaned_tokens_list = []\n",
    "negative_cleaned_tokens_list = []\n",
    "\n",
    "#Run through cleaning algorithm\n",
    "for tokens in positive_tweet_tokens:\n",
    "    positive_cleaned_tokens_list.append(remove_noise(tokens))\n",
    "\n",
    "#Run through cleaning algorithm\n",
    "for tokens in negative_tweet_tokens:\n",
    "    negative_cleaned_tokens_list.append(remove_noise(tokens))\n",
    "\n",
    "#Test to show words leftover\n",
    "#all_pos_words = get_all_words(positive_cleaned_tokens_list)\n",
    "\n",
    "# Return tokens for model\n",
    "positive_tokens_for_model = get_tokens_for_model(positive_cleaned_tokens_list)\n",
    "negative_tokens_for_model = get_tokens_for_model(negative_cleaned_tokens_list)\n",
    "\n",
    "# Form dataset\n",
    "positive_dataset = [(tweet_dict, \"Positive\")\n",
    "                     for tweet_dict in positive_tokens_for_model]\n",
    "\n",
    "negative_dataset = [(tweet_dict, \"Negative\")\n",
    "                     for tweet_dict in negative_tokens_for_model]\n",
    "\n",
    "dataset = positive_dataset + negative_dataset\n",
    "\n",
    "# Shuffle to randomize\n",
    "random.shuffle(dataset)\n",
    "\n",
    "# Break into training / testing datasets\n",
    "train_data = dataset[:7000]\n",
    "test_data = dataset[7000:]\n",
    "\n",
    "# Form classifier model\n",
    "classifier = NaiveBayesClassifier.train(train_data)\n",
    "\n",
    "# Print accuracy based on test data\n",
    "print(\"Accuracy is:\", classify.accuracy(classifier, test_data))\n",
    "print(classifier.show_most_informative_features(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With an accuracy of over 99.5%, I'm very confident of the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quick Manual Example of Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Positive'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = []\n",
    "\n",
    "sample_1 = 'I really like this idea, good job Steve!'\n",
    "sample_2 = 'This is the worst idea I have ever heard of, stop talking to me!'\n",
    "\n",
    "custom_tokens_1 = remove_noise(tweet_tknzr.tokenize(sample_1))\n",
    "custom_tokens_2 = remove_noise(tweet_tknzr.tokenize(sample_2))\n",
    "\n",
    "classifier.classify(dict([token, True] for token in custom_tokens_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Negative'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.classify(dict([token, True] for token in custom_tokens_2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test 1 - All Comment Analyis\n",
    "\n",
    "1. Pull all comments from 100 stories from three different political subreddits (Progressive, Conservative, NeutralPolitics)\n",
    "2. Run sentiment analysis on all three sets\n",
    "3. Compare sentiment percentage from each"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test 1 - Data Pull"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Assign subreddits and print out some basic info to test\n",
    "subreddits = [reddit.subreddit(\"Liberal\"),reddit.subreddit(\"Conservative\"),reddit.subreddit(\"NeutralPolitics\")]\n",
    "\n",
    "for subreddit in subreddits:\n",
    "    print(subreddit.display_name)\n",
    "    print(subreddit.description)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sample output (truncated due to length):\n",
    "\n",
    "<pre>Liberal\n",
    "**Welcome to /r/Liberal!**\n",
    "\n",
    "**Submission Guidelines**\n",
    "\n",
    "* Do not submit pictures\n",
    "* Do not submit videos\n",
    "* Do not submit memes...</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Grab ID's for 100 stories in each of the three subreddits (the \"hot\" 100)\n",
    "story_ids = {}\n",
    "\n",
    "for subreddit in subreddits:\n",
    "    for submission in subreddit.hot(limit=100):\n",
    "        \n",
    "        #Loop through comment hierarchy\n",
    "        while True:\n",
    "            try:\n",
    "                submission.comments.replace_more(limit=None) #Remove 'show more comments'\n",
    "                break\n",
    "            except PossibleExceptions:\n",
    "                print(\"Handling replace_more exception\")\n",
    "                sleep(1)\n",
    "\n",
    "        story_ids[submission.id] = [subreddit.display_name,submission.title,submission.comments.list()] #Put comments in dictionary\n",
    "        \n",
    "# These ID's allow us to pull the sentiment for each individual story per subreddit\n",
    "for key, value in story_ids.items():\n",
    "     print(key, '->', value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sample output (truncated due to length):\n",
    "\n",
    "<pre>mrmrmn -> ['Liberal', 'Nancy Pelosi Reveals Mitch McConnell Blocked Ruth Bader Ginsburg From Getting Capitol Rotunda Memorial', [Comment(id='guni694'), Comment(id='gun9kzd'), Comment(id='gun6g67'), Comment(id='gunrb5k'), Comment(id='guo43lv'), Comment(id='gun9pts'), Comment(id='gunzaij'), Comment(id='gunx3hm'), Comment(id='guo42tq'), Comment(id='guntl7b'), Comment(id='guo4i4j'), Comment(id='guo8isc'), Comment(id='guo51mi'), Comment(id='gunifpa'), Comment(id='gunp802'), Comment(id='gunrykp'), Comment(id='guoebi5'), Comment(id='guniiqg')]]\n",
    "mre2ul -> ['Liberal', 'US jobless claims plunge to 576,000, lowest since pandemic', [Comment(id='gult7hk'), Comment(id='guls41x'), Comment(id='gulldj6'), Comment(id='gunkas3'), Comment(id='gulu5i6'), Comment(id='gum344z'), Comment(id='gunbvb6'), Comment(id='gunkifd'), Comment(id='gunlj54'), Comment(id='gulv1lr'), Comment(id='gum4zjx'), Comment(id='gum21x4'), Comment(id='gumk6bn'), Comment(id='gumbkei'), Comment(id='guluu0u'), Comment(id='gulunt8'), Comment(id='gum8l81'), Comment(id='gumtfmq'), Comment(id='gum2ol0'), Comment(id='guluw2o')]]</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Post ID</th>\n",
       "      <th>Subreddit</th>\n",
       "      <th>Post Title</th>\n",
       "      <th>Comment ID</th>\n",
       "      <th>Score</th>\n",
       "      <th>Created</th>\n",
       "      <th>Body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mrmrmn</td>\n",
       "      <td>Liberal</td>\n",
       "      <td>Nancy Pelosi Reveals Mitch McConnell Blocked R...</td>\n",
       "      <td>guni694</td>\n",
       "      <td>16</td>\n",
       "      <td>1.618551e+09</td>\n",
       "      <td>What?! Holy shit!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mrmrmn</td>\n",
       "      <td>Liberal</td>\n",
       "      <td>Nancy Pelosi Reveals Mitch McConnell Blocked R...</td>\n",
       "      <td>gun9kzd</td>\n",
       "      <td>49</td>\n",
       "      <td>1.618547e+09</td>\n",
       "      <td>Does it really need to be revealed that Mitch ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mrmrmn</td>\n",
       "      <td>Liberal</td>\n",
       "      <td>Nancy Pelosi Reveals Mitch McConnell Blocked R...</td>\n",
       "      <td>gun6g67</td>\n",
       "      <td>26</td>\n",
       "      <td>1.618546e+09</td>\n",
       "      <td>Just horrible.\\n\\n\\n\\n&gt;“Mitch McConnell is not...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mrmrmn</td>\n",
       "      <td>Liberal</td>\n",
       "      <td>Nancy Pelosi Reveals Mitch McConnell Blocked R...</td>\n",
       "      <td>gunrb5k</td>\n",
       "      <td>9</td>\n",
       "      <td>1.618555e+09</td>\n",
       "      <td>Because of Course he did.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mrmrmn</td>\n",
       "      <td>Liberal</td>\n",
       "      <td>Nancy Pelosi Reveals Mitch McConnell Blocked R...</td>\n",
       "      <td>guo43lv</td>\n",
       "      <td>7</td>\n",
       "      <td>1.618562e+09</td>\n",
       "      <td>when fuck knuckle McConnell dies, please make ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Post ID Subreddit                                         Post Title  \\\n",
       "0  mrmrmn   Liberal  Nancy Pelosi Reveals Mitch McConnell Blocked R...   \n",
       "1  mrmrmn   Liberal  Nancy Pelosi Reveals Mitch McConnell Blocked R...   \n",
       "2  mrmrmn   Liberal  Nancy Pelosi Reveals Mitch McConnell Blocked R...   \n",
       "3  mrmrmn   Liberal  Nancy Pelosi Reveals Mitch McConnell Blocked R...   \n",
       "4  mrmrmn   Liberal  Nancy Pelosi Reveals Mitch McConnell Blocked R...   \n",
       "\n",
       "  Comment ID  Score       Created  \\\n",
       "0    guni694     16  1.618551e+09   \n",
       "1    gun9kzd     49  1.618547e+09   \n",
       "2    gun6g67     26  1.618546e+09   \n",
       "3    gunrb5k      9  1.618555e+09   \n",
       "4    guo43lv      7  1.618562e+09   \n",
       "\n",
       "                                                Body  \n",
       "0                                  What?! Holy shit!  \n",
       "1  Does it really need to be revealed that Mitch ...  \n",
       "2  Just horrible.\\n\\n\\n\\n>“Mitch McConnell is not...  \n",
       "3                          Because of Course he did.  \n",
       "4  when fuck knuckle McConnell dies, please make ...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dump comments into a pandas dataframe\n",
    "df_rows = []\n",
    "\n",
    "for key, value in story_ids.items():\n",
    "    # Loop through comment lists in value[2]\n",
    "    for comment in value[2]:\n",
    "        df_rows.append([key, value[0], value[1], comment.id, comment.score, comment.created, comment.body])\n",
    "\n",
    "df = pd.DataFrame(df_rows, columns=['Post ID', 'Subreddit', 'Post Title', 'Comment ID', 'Score', 'Created', 'Body'])\n",
    "df = df[(df['Body'] == '[deleted]') | (df['Body'] == '[removed]')==False].reset_index(drop=True) #Exclude any deleted/removed comments\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 17921 entries, 0 to 17920\n",
      "Data columns (total 7 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   Post ID     17921 non-null  object \n",
      " 1   Subreddit   17921 non-null  object \n",
      " 2   Post Title  17921 non-null  object \n",
      " 3   Comment ID  17921 non-null  object \n",
      " 4   Score       17921 non-null  int64  \n",
      " 5   Created     17921 non-null  float64\n",
      " 6   Body        17921 non-null  object \n",
      "dtypes: float64(1), int64(1), object(5)\n",
      "memory usage: 980.2+ KB\n"
     ]
    }
   ],
   "source": [
    "# Here we can see we have a total of ~18k comments\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test 1 - EDA\n",
    "\n",
    "1. Analyze all comments from 100 stories for sentiment, grouped by subreddit.\n",
    "2. Then, analyze all comments from 100 stories for sentiment, group by subreddit AND story ID (then aggregate)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gather sentiment for every comment and dump in list\n",
    "\n",
    "custom_tokens = []\n",
    "results = []\n",
    "num_pos = 0\n",
    "num_neg = 0\n",
    "per_pos = 0.0\n",
    "per_neg = 0.0\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    custom_tokens.append(remove_noise(tweet_tknzr.tokenize(row['Body'])))\n",
    "    results.append([row['Post ID'], row['Subreddit'], row['Body'], classifier.classify(dict([token, True] for token in custom_tokens[index]))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Sentiment</th>\n",
       "      <th>Negative</th>\n",
       "      <th>Positive</th>\n",
       "      <th>% Negative</th>\n",
       "      <th>% Positive</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Subreddit</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Conservative</th>\n",
       "      <td>3092</td>\n",
       "      <td>2862</td>\n",
       "      <td>51.93</td>\n",
       "      <td>48.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Liberal</th>\n",
       "      <td>662</td>\n",
       "      <td>599</td>\n",
       "      <td>52.50</td>\n",
       "      <td>47.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NeutralPolitics</th>\n",
       "      <td>5433</td>\n",
       "      <td>5273</td>\n",
       "      <td>50.75</td>\n",
       "      <td>49.25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Sentiment        Negative  Positive  % Negative  % Positive\n",
       "Subreddit                                                  \n",
       "Conservative         3092      2862       51.93       48.07\n",
       "Liberal               662       599       52.50       47.50\n",
       "NeutralPolitics      5433      5273       50.75       49.25"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Analyze sentiment gathered for all comments on all stories by subreddit\n",
    "# Display percentage\n",
    "\n",
    "df_r = pd.DataFrame([result[1:] for result in results], columns=['Subreddit','Body','Sentiment'])\n",
    "df_r_p = df_r[['Subreddit','Sentiment']].pivot_table(index='Subreddit', columns='Sentiment', aggfunc=len, fill_value=0)\n",
    "df_r_p['% Negative'] = round((df_r_p['Negative'] / (df_r_p['Positive'] + df_r_p['Negative'])) * 100,2)\n",
    "df_r_p['% Positive'] = round((df_r_p['Positive'] / (df_r_p['Positive'] + df_r_p['Negative'])) * 100,2)\n",
    "df_r_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Sampling of Pos/Neg Comments\n",
    "df_r[df_r['Sentiment'] == 'Negative']['Body'].tolist() #Negative"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sample output (truncated due to length):\n",
    "    \n",
    "<pre>['What?! Holy shit!',\n",
    " 'Does it really need to be revealed that Mitch McConnell is a cunt ?',\n",
    " 'when fuck knuckle McConnell dies, please make sure that his coffin is proudly displayed in a confederate flag draped dumpster',\n",
    " 'And yet Democrats still pretend they can work with these political arsonists.',\n",
    " 'Dick',\n",
    " 'Nancy is a gross too.',\n",
    " \"Just horrible.  I wasn't aware of this.\",\n",
    " 'No, but it needs to be said.  Repeatedly.',\n",
    " 'Nope.\\n\\n\\nThe cumulative analysis of everything he has done and said to hurt everyone in the USA?\\n\\n\\nAnd the support McConnell has shown disgraced insurrectionist and delusional one term former President Trump __(the only President to be impeached twice)__ is unfathomable.\\n\\n\\n\\n.',</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_r[df_r['Sentiment'] == 'Positive']['Body'].tolist() #Positive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sample output (truncated due to length):\n",
    "    \n",
    "<pre>['Just horrible.\\n\\n\\n\\n>“Mitch McConnell is not a force for good in our country,” Pelosi told me. “He is an enabler of some of the worst stuff, and an instigator of some of it on his own.” The two congressional leaders had never had a particularly good relationship. Now there was bitterness from a new dispute between them, one not reported at the time. When Supreme Court justice Ruth Bader Ginsburg died in September, Pelosi proposed that the groundbreaking feminist lie in state in the Capitol Rotunda. She would have been the first woman in history to be so honored.\\n\\n>McConnell rejected the idea on the grounds that there was no precedent for such treatment of a justice. When William Howard Taft had lain in state in 1930, he had been not only the chief justice but also president, McConnell noted.\\n\\n>He wasn’t swayed by the argument that Ginsburg had achieved an iconic status in American culture, especially for women and girls. McConnell’s refusal meant that Ginsburg’s flag-draped coffin was placed not in the Rotunda, which connects the House and Senate, but in Statuary Hall, on the House side.\\n\\n>McConnell and House Republican leader Kevin McCarthy didn’t accept invitations to attend the service for her.',\n",
    " 'Because of Course he did.',</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although we see a good breakdown by all comments, this may not account for the fact that a story could contain all positive or all negative comments - perhaps a better method of analysis would be to group the stories by ID first and obtain the percentages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Negative</th>\n",
       "      <th>Positive</th>\n",
       "      <th>% Negative</th>\n",
       "      <th>% Positive</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Subreddit</th>\n",
       "      <th>Post ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">Conservative</th>\n",
       "      <th>mr364d</th>\n",
       "      <td>536</td>\n",
       "      <td>611</td>\n",
       "      <td>46.73</td>\n",
       "      <td>53.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mr4lz8</th>\n",
       "      <td>39</td>\n",
       "      <td>35</td>\n",
       "      <td>52.70</td>\n",
       "      <td>47.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mr5564</th>\n",
       "      <td>201</td>\n",
       "      <td>228</td>\n",
       "      <td>46.85</td>\n",
       "      <td>53.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mrbef8</th>\n",
       "      <td>54</td>\n",
       "      <td>55</td>\n",
       "      <td>49.54</td>\n",
       "      <td>50.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mrbpev</th>\n",
       "      <td>57</td>\n",
       "      <td>36</td>\n",
       "      <td>61.29</td>\n",
       "      <td>38.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">NeutralPolitics</th>\n",
       "      <th>mgyhyz</th>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>25.00</td>\n",
       "      <td>75.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mm3oyu</th>\n",
       "      <td>197</td>\n",
       "      <td>124</td>\n",
       "      <td>61.37</td>\n",
       "      <td>38.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mm4eaw</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>50.00</td>\n",
       "      <td>50.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mmuprh</th>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>56.25</td>\n",
       "      <td>43.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mpaobl</th>\n",
       "      <td>11</td>\n",
       "      <td>6</td>\n",
       "      <td>64.71</td>\n",
       "      <td>35.29</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>285 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Sentiment                Negative  Positive  % Negative  % Positive\n",
       "Subreddit       Post ID                                            \n",
       "Conservative    mr364d        536       611       46.73       53.27\n",
       "                mr4lz8         39        35       52.70       47.30\n",
       "                mr5564        201       228       46.85       53.15\n",
       "                mrbef8         54        55       49.54       50.46\n",
       "                mrbpev         57        36       61.29       38.71\n",
       "...                           ...       ...         ...         ...\n",
       "NeutralPolitics mgyhyz          2         6       25.00       75.00\n",
       "                mm3oyu        197       124       61.37       38.63\n",
       "                mm4eaw          2         2       50.00       50.00\n",
       "                mmuprh          9         7       56.25       43.75\n",
       "                mpaobl         11         6       64.71       35.29\n",
       "\n",
       "[285 rows x 4 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Analyze sentiment gathered for all comments on all stories by subreddit AND story ID\n",
    "# Display percentage\n",
    "\n",
    "df_r = pd.DataFrame(results, columns=['Post ID','Subreddit','Body','Sentiment'])\n",
    "df_r_p = df_r[['Post ID','Subreddit','Sentiment']].pivot_table(index=['Subreddit','Post ID'], columns='Sentiment', aggfunc=len, fill_value=0)\n",
    "df_r_p['% Negative'] = round((df_r_p['Negative'] / (df_r_p['Positive'] + df_r_p['Negative'])) * 100,2)\n",
    "df_r_p['% Positive'] = round((df_r_p['Positive'] / (df_r_p['Positive'] + df_r_p['Negative'])) * 100,2)\n",
    "df_r_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Negative</th>\n",
       "      <th>Positive</th>\n",
       "      <th>% Negative</th>\n",
       "      <th>% Positive</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Subreddit</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Conservative</th>\n",
       "      <td>3092</td>\n",
       "      <td>2862</td>\n",
       "      <td>52.67</td>\n",
       "      <td>47.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Liberal</th>\n",
       "      <td>662</td>\n",
       "      <td>599</td>\n",
       "      <td>49.19</td>\n",
       "      <td>50.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NeutralPolitics</th>\n",
       "      <td>5433</td>\n",
       "      <td>5273</td>\n",
       "      <td>47.95</td>\n",
       "      <td>52.05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Negative  Positive  % Negative  % Positive\n",
       "Subreddit                                                  \n",
       "Conservative         3092      2862       52.67       47.33\n",
       "Liberal               662       599       49.19       50.81\n",
       "NeutralPolitics      5433      5273       47.95       52.05"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Group by Subreddit and take average of averages\n",
    "df_r_p.groupby('Subreddit').agg({'Negative':'sum', \n",
    "                         'Positive':'sum', \n",
    "                         '% Negative':'mean', \n",
    "                         '% Positive':'mean'}).round(decimals=2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test 1 - Conclusion\n",
    "In testing through several iterations - I've found that there tends to be a fairly direct lean towards negative in the top 100 (sometimes more than others).\n",
    "\n",
    "The only problem with taking a percentage grouped by only subreddit is that is ignores the story id's and therefore may produce skewed numbers in which a story could be all positive or all negative.\n",
    "\n",
    "We can try to account for this by including the story ID in the groupby and take an average of averages. Doing so highlights that the Conservative subreddit tends to skew more towards a more negative sentiment, while Liberal and NeutralPolitics subreddits tend to sit <i>more</i> in the middle (although we're dealing in very small percentages here).\n",
    "\n",
    "Another way to put it, is that for every negative comment posted on a given story in Liberal/NeutralPolitics - there appears to be at least one positive comment as well when normalizing by grouping by Post ID first.\n",
    "\n",
    "However - when viewing what the model claims is positive/negative, we can easily pick out quite a few items that most would have thrown into the negative column instead of positive. This may go both ways, but I have a feeling that the negative skew should be even higher. With time to train using other data we might be able to produce more accurate results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test 2 - Top-level Analysis Only\n",
    "\n",
    "With all of these data pulls we've been making the assumption that we should pull the entirety of all comments on a story and NOT only the top-level comments. The only problem this represents is that we may now be pulling large threads of discussion in which folks could be arguing back and forth on the subject, thereby skewing negativity. If we try only pulling the top-level comments, perhaps we can get a better sense of the initial reaction from each user.\n",
    "\n",
    "1. Analyze top-level comments from 100 stories for sentiment, grouped by subreddit.\n",
    "2. Then, analyze top-level comments from 100 stories for sentiment, group by subreddit AND story ID (then aggregate)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test 2 - Data Pull"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Assign subreddits and print out some basic info to test\n",
    "subreddits = [reddit.subreddit(\"Liberal\"),reddit.subreddit(\"Conservative\"),reddit.subreddit(\"NeutralPolitics\")]\n",
    "\n",
    "# Grab ID's for 100 stories in each subreddit (the \"hot\" 100)\n",
    "story_ids = {}\n",
    "\n",
    "for subreddit in subreddits:\n",
    "    for submission in subreddit.hot(limit=100):\n",
    "        \n",
    "        #Loop through comment hierarchy and pull all levels\n",
    "        while True:\n",
    "            try:\n",
    "                submission.comments.replace_more(limit=None) #Remove 'show more comments'\n",
    "                break\n",
    "            except PossibleExceptions:\n",
    "                print(\"Handling replace_more exception\")\n",
    "                sleep(1)\n",
    "        \n",
    "        #Pull only top-level comments\n",
    "        story_ids[submission.id] = [subreddit.display_name,submission.title,[top_level_comment for top_level_comment in submission.comments]] #Put in dictionary\n",
    "        \n",
    "# These ID's allow us to pull the sentiment for each individual story per subreddit\n",
    "for key, value in story_ids.items():\n",
    "     print(key, '->', value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sample output (truncated due to length):\n",
    "    \n",
    "<pre>mrmrmn -> ['Liberal', 'Nancy Pelosi Reveals Mitch McConnell Blocked Ruth Bader Ginsburg From Getting Capitol Rotunda Memorial', [Comment(id='guni694'), Comment(id='gun9kzd'), Comment(id='gun6g67'), Comment(id='gunrb5k'), Comment(id='guo43lv'), Comment(id='gun9pts'), Comment(id='gunzaij'), Comment(id='guo42tq'), Comment(id='gunx3hm'), Comment(id='guntl7b'), Comment(id='guo4i4j'), Comment(id='guo8isc'), Comment(id='guo51mi')]]\n",
    "mre2ul -> ['Liberal', 'US jobless claims plunge to 576,000, lowest since pandemic', [Comment(id='gult7hk'), Comment(id='guls41x'), Comment(id='gulldj6'), Comment(id='gunkas3'), Comment(id='gulu5i6')]]\n",
    "mrbjf5 -> ['Liberal', 'Democrats to introduce legislation to expand Supreme Court', [Comment(id='gum7bf4'), Comment(id='gum2scd'), Comment(id='gummtcu'), Comment(id='gum40vp'), Comment(id='gultr3g'), Comment(id='gulykpg'), Comment(id='guls3mm'), Comment(id='gune3t6'), Comment(id='gunk109'), Comment(id='gunts3x'), Comment(id='guo4vo6'), Comment(id='gumx8eh')]]\n",
    "mrqzy2 -> ['Liberal', 'Nice! Schumer lays groundwork for future filibuster reform', []]\n",
    "mrqbbo -> ['Liberal', 'Biden: ‘If Russia continues to interfere with our democracy, I’m prepared to take further actions’', []]\n",
    "mrf49t -> ['Liberal', 'Biden Administration to Impose Tough Sanctions on Russia', [Comment(id='gum3jcu')]]\n",
    "mrqjr4 -> ['Liberal', \"WATCH: Maxine Waters erupts at Jim Jordan and tells him to 'respect the chair and shut your mouth' during COVID-19 hearing\", [Comment(id='guo6h7f'), Comment(id='gunvd63')]]</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Post ID</th>\n",
       "      <th>Subreddit</th>\n",
       "      <th>Post Title</th>\n",
       "      <th>Comment ID</th>\n",
       "      <th>Score</th>\n",
       "      <th>Created</th>\n",
       "      <th>Body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mrmrmn</td>\n",
       "      <td>Liberal</td>\n",
       "      <td>Nancy Pelosi Reveals Mitch McConnell Blocked R...</td>\n",
       "      <td>guni694</td>\n",
       "      <td>17</td>\n",
       "      <td>1.618551e+09</td>\n",
       "      <td>What?! Holy shit!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mrmrmn</td>\n",
       "      <td>Liberal</td>\n",
       "      <td>Nancy Pelosi Reveals Mitch McConnell Blocked R...</td>\n",
       "      <td>gun9kzd</td>\n",
       "      <td>50</td>\n",
       "      <td>1.618547e+09</td>\n",
       "      <td>Does it really need to be revealed that Mitch ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mrmrmn</td>\n",
       "      <td>Liberal</td>\n",
       "      <td>Nancy Pelosi Reveals Mitch McConnell Blocked R...</td>\n",
       "      <td>gun6g67</td>\n",
       "      <td>27</td>\n",
       "      <td>1.618546e+09</td>\n",
       "      <td>Just horrible.\\n\\n\\n\\n&gt;“Mitch McConnell is not...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mrmrmn</td>\n",
       "      <td>Liberal</td>\n",
       "      <td>Nancy Pelosi Reveals Mitch McConnell Blocked R...</td>\n",
       "      <td>gunrb5k</td>\n",
       "      <td>7</td>\n",
       "      <td>1.618555e+09</td>\n",
       "      <td>Because of Course he did.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mrmrmn</td>\n",
       "      <td>Liberal</td>\n",
       "      <td>Nancy Pelosi Reveals Mitch McConnell Blocked R...</td>\n",
       "      <td>guo43lv</td>\n",
       "      <td>6</td>\n",
       "      <td>1.618562e+09</td>\n",
       "      <td>when fuck knuckle McConnell dies, please make ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Post ID Subreddit                                         Post Title  \\\n",
       "0  mrmrmn   Liberal  Nancy Pelosi Reveals Mitch McConnell Blocked R...   \n",
       "1  mrmrmn   Liberal  Nancy Pelosi Reveals Mitch McConnell Blocked R...   \n",
       "2  mrmrmn   Liberal  Nancy Pelosi Reveals Mitch McConnell Blocked R...   \n",
       "3  mrmrmn   Liberal  Nancy Pelosi Reveals Mitch McConnell Blocked R...   \n",
       "4  mrmrmn   Liberal  Nancy Pelosi Reveals Mitch McConnell Blocked R...   \n",
       "\n",
       "  Comment ID  Score       Created  \\\n",
       "0    guni694     17  1.618551e+09   \n",
       "1    gun9kzd     50  1.618547e+09   \n",
       "2    gun6g67     27  1.618546e+09   \n",
       "3    gunrb5k      7  1.618555e+09   \n",
       "4    guo43lv      6  1.618562e+09   \n",
       "\n",
       "                                                Body  \n",
       "0                                  What?! Holy shit!  \n",
       "1  Does it really need to be revealed that Mitch ...  \n",
       "2  Just horrible.\\n\\n\\n\\n>“Mitch McConnell is not...  \n",
       "3                          Because of Course he did.  \n",
       "4  when fuck knuckle McConnell dies, please make ...  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dump comments into a pandas dataframe\n",
    "df_rows = []\n",
    "\n",
    "for key, value in story_ids.items():\n",
    "    # Loop through comment lists in value[2]\n",
    "    for comment in value[2]:\n",
    "        df_rows.append([key, value[0], value[1], comment.id, comment.score, comment.created, comment.body])\n",
    "\n",
    "df = pd.DataFrame(df_rows, columns=['Post ID', 'Subreddit', 'Post Title', 'Comment ID', 'Score', 'Created', 'Body'])\n",
    "df = df[(df['Body'] == '[deleted]') | (df['Body'] == '[removed]')==False].reset_index(drop=True) #Exclude any deleted/removed comments\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2890 entries, 0 to 2889\n",
      "Data columns (total 7 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   Post ID     2890 non-null   object \n",
      " 1   Subreddit   2890 non-null   object \n",
      " 2   Post Title  2890 non-null   object \n",
      " 3   Comment ID  2890 non-null   object \n",
      " 4   Score       2890 non-null   int64  \n",
      " 5   Created     2890 non-null   float64\n",
      " 6   Body        2890 non-null   object \n",
      "dtypes: float64(1), int64(1), object(5)\n",
      "memory usage: 158.2+ KB\n"
     ]
    }
   ],
   "source": [
    "# Very limited set now at 2890 comments, compared to 18k\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test 2 - EDA\n",
    "1. Analyze all top-level comments from 100 stories for sentiment, grouped by subreddit.\n",
    "2. Then, analyze all top-level comments from 100 stories for sentiment, group by subreddit AND story ID (then aggregate)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gather sentiment for every comment and dump in list\n",
    "\n",
    "custom_tokens = []\n",
    "results = []\n",
    "num_pos = 0\n",
    "num_neg = 0\n",
    "per_pos = 0.0\n",
    "per_neg = 0.0\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    custom_tokens.append(remove_noise(tweet_tknzr.tokenize(row['Body'])))\n",
    "    results.append([row['Post ID'], row['Subreddit'], row['Body'], classifier.classify(dict([token, True] for token in custom_tokens[index]))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Sentiment</th>\n",
       "      <th>Negative</th>\n",
       "      <th>Positive</th>\n",
       "      <th>% Negative</th>\n",
       "      <th>% Positive</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Subreddit</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Conservative</th>\n",
       "      <td>866</td>\n",
       "      <td>789</td>\n",
       "      <td>52.33</td>\n",
       "      <td>47.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Liberal</th>\n",
       "      <td>261</td>\n",
       "      <td>227</td>\n",
       "      <td>53.48</td>\n",
       "      <td>46.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NeutralPolitics</th>\n",
       "      <td>238</td>\n",
       "      <td>509</td>\n",
       "      <td>31.86</td>\n",
       "      <td>68.14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Sentiment        Negative  Positive  % Negative  % Positive\n",
       "Subreddit                                                  \n",
       "Conservative          866       789       52.33       47.67\n",
       "Liberal               261       227       53.48       46.52\n",
       "NeutralPolitics       238       509       31.86       68.14"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Analyze sentiment gathered for top-level comments on all stories by subreddit\n",
    "# Display percentage\n",
    "\n",
    "df_r = pd.DataFrame([result[1:] for result in results], columns=['Subreddit','Body','Sentiment'])\n",
    "df_r_p = df_r[['Subreddit','Sentiment']].pivot_table(index='Subreddit', columns='Sentiment', aggfunc=len, fill_value=0)\n",
    "df_r_p['% Negative'] = round((df_r_p['Negative'] / (df_r_p['Positive'] + df_r_p['Negative'])) * 100,2)\n",
    "df_r_p['% Positive'] = round((df_r_p['Positive'] / (df_r_p['Positive'] + df_r_p['Negative'])) * 100,2)\n",
    "df_r_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Negative</th>\n",
       "      <th>Positive</th>\n",
       "      <th>% Negative</th>\n",
       "      <th>% Positive</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Subreddit</th>\n",
       "      <th>Post ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">Conservative</th>\n",
       "      <th>mr364d</th>\n",
       "      <td>97</td>\n",
       "      <td>112</td>\n",
       "      <td>46.41</td>\n",
       "      <td>53.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mr4lz8</th>\n",
       "      <td>14</td>\n",
       "      <td>20</td>\n",
       "      <td>41.18</td>\n",
       "      <td>58.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mr5564</th>\n",
       "      <td>32</td>\n",
       "      <td>36</td>\n",
       "      <td>47.06</td>\n",
       "      <td>52.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mrbef8</th>\n",
       "      <td>16</td>\n",
       "      <td>9</td>\n",
       "      <td>64.00</td>\n",
       "      <td>36.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mrbpev</th>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>66.67</td>\n",
       "      <td>33.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">NeutralPolitics</th>\n",
       "      <th>mgyhyz</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>100.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mm3oyu</th>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>75.00</td>\n",
       "      <td>25.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mm4eaw</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>33.33</td>\n",
       "      <td>66.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mmuprh</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>100.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mpaobl</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>75.00</td>\n",
       "      <td>25.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>285 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Sentiment                Negative  Positive  % Negative  % Positive\n",
       "Subreddit       Post ID                                            \n",
       "Conservative    mr364d         97       112       46.41       53.59\n",
       "                mr4lz8         14        20       41.18       58.82\n",
       "                mr5564         32        36       47.06       52.94\n",
       "                mrbef8         16         9       64.00       36.00\n",
       "                mrbpev          6         3       66.67       33.33\n",
       "...                           ...       ...         ...         ...\n",
       "NeutralPolitics mgyhyz          0         2        0.00      100.00\n",
       "                mm3oyu          6         2       75.00       25.00\n",
       "                mm4eaw          1         2       33.33       66.67\n",
       "                mmuprh          0         5        0.00      100.00\n",
       "                mpaobl          3         1       75.00       25.00\n",
       "\n",
       "[285 rows x 4 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Analyze sentiment gathered for top-level comments on all stories by subreddit AND story ID\n",
    "# Display percentage\n",
    "\n",
    "df_r = pd.DataFrame(results, columns=['Post ID','Subreddit','Body','Sentiment'])\n",
    "df_r_p = df_r[['Post ID','Subreddit','Sentiment']].pivot_table(index=['Subreddit','Post ID'], columns='Sentiment', aggfunc=len, fill_value=0)\n",
    "df_r_p['% Negative'] = round((df_r_p['Negative'] / (df_r_p['Positive'] + df_r_p['Negative'])) * 100,2)\n",
    "df_r_p['% Positive'] = round((df_r_p['Positive'] / (df_r_p['Positive'] + df_r_p['Negative'])) * 100,2)\n",
    "df_r_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Negative</th>\n",
       "      <th>Positive</th>\n",
       "      <th>% Negative</th>\n",
       "      <th>% Positive</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Subreddit</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Conservative</th>\n",
       "      <td>866</td>\n",
       "      <td>789</td>\n",
       "      <td>51.20</td>\n",
       "      <td>48.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Liberal</th>\n",
       "      <td>261</td>\n",
       "      <td>227</td>\n",
       "      <td>50.12</td>\n",
       "      <td>49.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NeutralPolitics</th>\n",
       "      <td>238</td>\n",
       "      <td>509</td>\n",
       "      <td>29.40</td>\n",
       "      <td>70.60</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Negative  Positive  % Negative  % Positive\n",
       "Subreddit                                                  \n",
       "Conservative          866       789       51.20       48.80\n",
       "Liberal               261       227       50.12       49.88\n",
       "NeutralPolitics       238       509       29.40       70.60"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Group by Subreddit and take average of averages\n",
    "df_r_p.groupby('Subreddit').agg({'Negative':'sum', \n",
    "                         'Positive':'sum', \n",
    "                         '% Negative':'mean', \n",
    "                         '% Positive':'mean'}).round(decimals=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test 2 - Conclusion\n",
    "\n",
    "Surprisingly (at least to me), taking into account only top-level comments shows a huge move towards positive for NeutralPolitics. This seems to indicate that discussion within the subreddit is quite balanced, but initial top-level responses are biased towards positivity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test 3\n",
    "\n",
    "1. Pull same story from two different subreddits that are ideologically different\n",
    "2. Run sentiment analysis on all sets\n",
    "3. Compare sentiment percentage from each\n",
    "\n",
    "In this case - I'll take a look at two different stories posted on the same topic within the Conservative subreddit, and the subreddit called \"Politics\". This subreddit tends to lean center-left naturally due to the user base of Reddit.com. This should at least give us an idea how right vs. left respond to differently or similarly to the same story.\n",
    "\n",
    "In this case, it's a story detailing the ban of the subreddit \"The_Donald\", a far-right subreddit that was the center of much controversy. You would assume that the conservative leaning subreddit would produce more negative sentiment, while the center-left would produce more positive sentiment on the banning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test 3 - Algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def returnAllComments():\n",
    "    '''\n",
    "    Return all comments from a given submission into a DataFrame\n",
    "    '''\n",
    "    #Loop through comment hierarchy and pull all levels\n",
    "    df_rows = []\n",
    "\n",
    "    #Loop through comment hierarchy\n",
    "    while True:\n",
    "        try:\n",
    "            submission.comments.replace_more(limit=None) #Flatten comment tree\n",
    "            break\n",
    "        except PossibleExceptions:\n",
    "            print(\"Handling replace_more exception\")\n",
    "            sleep(1)\n",
    "\n",
    "    comments = submission.comments.list() #Move to list\n",
    "\n",
    "    # Loop through comment lists\n",
    "    for comment in comments:\n",
    "        df_rows.append([comment.id, comment.score, comment.created, comment.body])\n",
    "\n",
    "    df = pd.DataFrame(df_rows, columns=['Comment ID', 'Score', 'Created', 'Body'])\n",
    "    return df[(df['Body'] == '[deleted]') | (df['Body'] == '[removed]')==False].reset_index(drop=True) #Exclude any deleted/removed comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def runSingleStorySentimentAnalysis(df):\n",
    "    '''\n",
    "    Run sentiment analysis on a given DataFrame and return analysis\n",
    "    '''\n",
    "    # Gather sentiment for every comment and dump in list\n",
    "    custom_tokens = []\n",
    "    results = []\n",
    "    num_pos = 0\n",
    "    num_neg = 0\n",
    "    per_pos = 0.0\n",
    "    per_neg = 0.0\n",
    "\n",
    "    for index, row in df.iterrows():\n",
    "        custom_tokens.append(remove_noise(tweet_tknzr.tokenize(row['Body'])))\n",
    "        results.append([classifier.classify(dict([token, True] for token in custom_tokens[index]))])\n",
    "\n",
    "    # Display percentages\n",
    "    df_r = pd.DataFrame([result for result in results], columns=['Sentiment'])\n",
    "    df_r_p = pd.DataFrame(df_r.groupby('Sentiment').size(), columns=['Count'])\n",
    "    df_r_p['% of Total'] = round((df_r_p / df_r_p.sum())*100,2)\n",
    "    return df_r_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def returnComments(df):\n",
    "    '''\n",
    "    Run sentiment analysis on a given DataFrame and return detail results to review\n",
    "    '''\n",
    "    # Gather sentiment for every comment and dump in list\n",
    "    custom_tokens = []\n",
    "    results = []\n",
    "    num_pos = 0\n",
    "    num_neg = 0\n",
    "    per_pos = 0.0\n",
    "    per_neg = 0.0\n",
    "\n",
    "    for index, row in df.iterrows():\n",
    "        custom_tokens.append(remove_noise(tweet_tknzr.tokenize(row['Body'])))\n",
    "        results.append([row['Body'], classifier.classify(dict([token, True] for token in custom_tokens[index]))])\n",
    "       \n",
    "    #df_r = pd.DataFrame([result for result in results], columns=['Body','Sentiment'])\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test 3 - Conservative Subreddit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reddit bans The_Donald forum as part of major hate speech purge\n"
     ]
    }
   ],
   "source": [
    "# https://www.reddit.com/r/Conservative/comments/hi3u79/reddit_bans_the_donald_forum_as_part_of_major/\n",
    "    \n",
    "submission = reddit.submission(id=\"hi3u79\")\n",
    "print(submission.title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Comment ID</th>\n",
       "      <th>Score</th>\n",
       "      <th>Created</th>\n",
       "      <th>Body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>fwdvdws</td>\n",
       "      <td>52</td>\n",
       "      <td>1.593480e+09</td>\n",
       "      <td>R/consumeproduct was banned as well. RIP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>fwdv7gi</td>\n",
       "      <td>258</td>\n",
       "      <td>1.593480e+09</td>\n",
       "      <td>It’s been inactive for months lol. Good work r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>fwe2ike</td>\n",
       "      <td>40</td>\n",
       "      <td>1.593483e+09</td>\n",
       "      <td>Lol the press will focus on this matter and me...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>fwdup9y</td>\n",
       "      <td>356</td>\n",
       "      <td>1.593480e+09</td>\n",
       "      <td>Yet r/politics remains...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>fwdueft</td>\n",
       "      <td>65</td>\n",
       "      <td>1.593479e+09</td>\n",
       "      <td>I thought this was already taken down?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>423</th>\n",
       "      <td>fwgu2vy</td>\n",
       "      <td>1</td>\n",
       "      <td>1.593548e+09</td>\n",
       "      <td>It doesn't need to be on point to make the arg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>424</th>\n",
       "      <td>fwff5le</td>\n",
       "      <td>1</td>\n",
       "      <td>1.593508e+09</td>\n",
       "      <td>&gt; Yet I maintain that PoC who experience oppre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>425</th>\n",
       "      <td>fwinuo2</td>\n",
       "      <td>1</td>\n",
       "      <td>1.593581e+09</td>\n",
       "      <td>says the person who still somehow supports a r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>426</th>\n",
       "      <td>fwiv93o</td>\n",
       "      <td>1</td>\n",
       "      <td>1.593585e+09</td>\n",
       "      <td>Can’t argue with stupid so I shall stop lol</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>427</th>\n",
       "      <td>fwj2hzb</td>\n",
       "      <td>0</td>\n",
       "      <td>1.593588e+09</td>\n",
       "      <td>Yep! Trump indeed hates it when people call hi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>428 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Comment ID  Score       Created  \\\n",
       "0      fwdvdws     52  1.593480e+09   \n",
       "1      fwdv7gi    258  1.593480e+09   \n",
       "2      fwe2ike     40  1.593483e+09   \n",
       "3      fwdup9y    356  1.593480e+09   \n",
       "4      fwdueft     65  1.593479e+09   \n",
       "..         ...    ...           ...   \n",
       "423    fwgu2vy      1  1.593548e+09   \n",
       "424    fwff5le      1  1.593508e+09   \n",
       "425    fwinuo2      1  1.593581e+09   \n",
       "426    fwiv93o      1  1.593585e+09   \n",
       "427    fwj2hzb      0  1.593588e+09   \n",
       "\n",
       "                                                  Body  \n",
       "0             R/consumeproduct was banned as well. RIP  \n",
       "1    It’s been inactive for months lol. Good work r...  \n",
       "2    Lol the press will focus on this matter and me...  \n",
       "3                            Yet r/politics remains...  \n",
       "4               I thought this was already taken down?  \n",
       "..                                                 ...  \n",
       "423  It doesn't need to be on point to make the arg...  \n",
       "424  > Yet I maintain that PoC who experience oppre...  \n",
       "425  says the person who still somehow supports a r...  \n",
       "426        Can’t argue with stupid so I shall stop lol  \n",
       "427  Yep! Trump indeed hates it when people call hi...  \n",
       "\n",
       "[428 rows x 4 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = returnAllComments()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Count</th>\n",
       "      <th>% of Total</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sentiment</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Negative</th>\n",
       "      <td>236</td>\n",
       "      <td>55.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Positive</th>\n",
       "      <td>192</td>\n",
       "      <td>44.86</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Count  % of Total\n",
       "Sentiment                   \n",
       "Negative     236       55.14\n",
       "Positive     192       44.86"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "runSingleStorySentimentAnalysis(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "returnComments(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sample output (truncated due to length):\n",
    "\n",
    "<pre>[['R/consumeproduct was banned as well. RIP', 'Negative'],\n",
    " ['It’s been inactive for months lol. Good work reddit. You effectively did nothing.',\n",
    "  'Negative'],\n",
    " ['Lol the press will focus on this matter and mention r/the_donald only because they can up the antitrump ante. The sub was effectively a dead stump of its former self, so its like a beating the dead horse, but well you can always milk it for antitrump hate.',\n",
    "  'Negative'],\n",
    " ['Yet r/politics remains...', 'Negative'],\n",
    " ['I thought this was already taken down?', 'Negative'],\n",
    " ['Major “you don’t fit that narrative” purge. 1984', 'Negative'],\n",
    " ['Official reddit policy now *explicitly* allows hate subreddits/comments/posts against identities in the \"majority.\"',\n",
    "  'Positive'],\n",
    " ['\"hate speech\"? Someone misspelled \"political speech\"', 'Negative'],\n",
    " [\"Let them ban all the right leaning subs. And then still be shocked when Trump wins the election again.\\n\\nI cam't wait for the left crying compilation\",\n",
    "  'Negative'],</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interesting enough, the sentiment does lean negative - but only by 10 percentage points.\n",
    "\n",
    "### Test 3 - Liberal Subreddit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reddit Finally Bans Hate Speech, Removes 2,000 Racist and Violent Forums Including The_Donald\n"
     ]
    }
   ],
   "source": [
    "#https://www.reddit.com/r/Liberal/comments/hi4eva/reddit_finally_bans_hate_speech_removes_2000/\n",
    "\n",
    "submission = reddit.submission(id=\"hi4eva\")\n",
    "print(submission.title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Comment ID</th>\n",
       "      <th>Score</th>\n",
       "      <th>Created</th>\n",
       "      <th>Body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>fwe135b</td>\n",
       "      <td>59</td>\n",
       "      <td>1.593482e+09</td>\n",
       "      <td>Except the Canadian racist cesspool r/metacana...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>fweaghv</td>\n",
       "      <td>140</td>\n",
       "      <td>1.593487e+09</td>\n",
       "      <td>Republicans: \"Businesses should be allowed to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>fwfdwlw</td>\n",
       "      <td>14</td>\n",
       "      <td>1.593507e+09</td>\n",
       "      <td>Genuinely curious what the general consensus i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>fwdyo8v</td>\n",
       "      <td>48</td>\n",
       "      <td>1.593481e+09</td>\n",
       "      <td>About fucking time.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>fwe2p19</td>\n",
       "      <td>31</td>\n",
       "      <td>1.593483e+09</td>\n",
       "      <td>Words cannot express how fuckin happy I am rig...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>fwekx5v</td>\n",
       "      <td>-4</td>\n",
       "      <td>1.593492e+09</td>\n",
       "      <td>I never once said we should be deciding what s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>fwfpf4o</td>\n",
       "      <td>1</td>\n",
       "      <td>1.593514e+09</td>\n",
       "      <td>To your first point:\\n1. Looking back at my pr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>fwel0fe</td>\n",
       "      <td>3</td>\n",
       "      <td>1.593492e+09</td>\n",
       "      <td>How do you think that is different?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>fwfsr0t</td>\n",
       "      <td>1</td>\n",
       "      <td>1.593516e+09</td>\n",
       "      <td>Ok so since I haven’t made this clear no matte...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>fwfwurw</td>\n",
       "      <td>1</td>\n",
       "      <td>1.593518e+09</td>\n",
       "      <td>I agree with all your points. I just see a wor...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>189 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Comment ID  Score       Created  \\\n",
       "0      fwe135b     59  1.593482e+09   \n",
       "1      fweaghv    140  1.593487e+09   \n",
       "2      fwfdwlw     14  1.593507e+09   \n",
       "3      fwdyo8v     48  1.593481e+09   \n",
       "4      fwe2p19     31  1.593483e+09   \n",
       "..         ...    ...           ...   \n",
       "184    fwekx5v     -4  1.593492e+09   \n",
       "185    fwfpf4o      1  1.593514e+09   \n",
       "186    fwel0fe      3  1.593492e+09   \n",
       "187    fwfsr0t      1  1.593516e+09   \n",
       "188    fwfwurw      1  1.593518e+09   \n",
       "\n",
       "                                                  Body  \n",
       "0    Except the Canadian racist cesspool r/metacana...  \n",
       "1    Republicans: \"Businesses should be allowed to ...  \n",
       "2    Genuinely curious what the general consensus i...  \n",
       "3                                  About fucking time.  \n",
       "4    Words cannot express how fuckin happy I am rig...  \n",
       "..                                                 ...  \n",
       "184  I never once said we should be deciding what s...  \n",
       "185  To your first point:\\n1. Looking back at my pr...  \n",
       "186                How do you think that is different?  \n",
       "187  Ok so since I haven’t made this clear no matte...  \n",
       "188  I agree with all your points. I just see a wor...  \n",
       "\n",
       "[189 rows x 4 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = returnAllComments()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Count</th>\n",
       "      <th>% of Total</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sentiment</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Negative</th>\n",
       "      <td>112</td>\n",
       "      <td>59.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Positive</th>\n",
       "      <td>77</td>\n",
       "      <td>40.74</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Count  % of Total\n",
       "Sentiment                   \n",
       "Negative     112       59.26\n",
       "Positive      77       40.74"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "runSingleStorySentimentAnalysis(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Show details of how comments were classified\n",
    "returnComments(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sample output (truncated due to length):\n",
    "    \n",
    "<pre>[['Except the Canadian racist cesspool r/metacanada.\\n\\nStill waiting.......',\n",
    "  'Negative'],\n",
    " ['Republicans: \"Businesses should be allowed to reject any customer under any circumstances!\"  \\n  \\nAlso Republicans:  \"Reddit shouldn\\'t be allowed to reject any customer under any circumstances!\"',\n",
    "  'Positive'],\n",
    " ['Genuinely curious what the general consensus is about the part that says it does not protect the majority. Seems discriminatory.\\n\\n>While the rule on hate protects such groups, it does not protect all groups or all forms of identity. For example, the rule does not protect groups of people who are in the majority',\n",
    "  'Negative'],\n",
    " ['About fucking time.', 'Negative'],\n",
    " ['Words cannot express how fuckin happy I am right now!', 'Negative'],\n",
    " ['Did they ban all the subscribers too or just the reddit?', 'Negative'],\n",
    " ['This isn\\'t to all of you, but it\\'s to enough of you...\\n\\nWhat disabled person asked anyone to defend us from words?  I don\\'t even remember electing a representative for that... Trying to \"protect\" me from words is actually pretty rude.</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test 3 - Conclusion\n",
    "\n",
    "In this instance - we see a single story that is producing \"mostly\" negative comments within both subreddits. This result shows that sentiment is highly subjective, and that you cannot always simply infer that something will be seen is more positive or negative just because of the political leanings. In addition, this also shows that sentiment is once again very difficult in context. Although many negative comments from the subreddit Liberal are based upon the fact that censorship is wrong, many comments are classified as negative when in fact the comment being made is agreeing with the ban. These comments are marked as negative simply because of verbiage and not context. Either way, in this case, there still seems to be a lot of common ground being found within all users."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
